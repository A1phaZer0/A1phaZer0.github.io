---
title: "Heap Exploitation"
author: A1phaZer0
layout: post
category: Hacks
---
> **Chunks Arenas Heaps**

```bash
+===============+ high
|               |
|               |
|_______________|
|___size|flag___|
|///prev_size///|-+ <- mchunkptr (top chunk/wilderness chunk) 
|///////////////| |
|///////////////| user data
|//////bk///////| |
|//////fd///////|-+
|///size|flag///|
|___prev_size___|<- mchunkptr               ^
|               |                           |   backward
|               |                           |      |
|_______________|<- allocated buf/obj    forward   |
|___size|flag___|                                  v
|___prev_size___|<- mchunkptr
```

Shadow part in the figure represents a chunk, there are more about this:
* `prev_size == size` of the chunk.
* `mchunkptr` dosen't point to beginning of the chunk, but 4bytes(32bit OS) `ahead`.
* `flag` is `A|M|P` which means `Allocated Arena/Non-main Arena`, `Is Mmapped`, `Prev In-use` respectively.
* If `A` is set, the chunk comes from a arena of a `mmap() allocated heap`, otherwise the chunk is in main arena of the executable's heap.
* If `M` is set, the chunk is directly allocated by `mmap()` and is not a part of any heap.

If chunk is in a `mmap() allocated heap`, and since `heap_info` is at the start of mmap() allocated heap which is aligned with `HEAP_MAX_SIZE`, hence it can be found by the macro below. From `heap_info`, we can reach `arena`.  
```cpp
 #define heap_for_ptr(ptr) \                                   
      ((heap_info *)((unsigned long)(ptr) & ~(HEAP_MAX_SIZE-1)))
```
`ptr`: `mchunkptr`.  

But how to find `arena` of a chunk in main arena? `main_arena`, a static variable in the malloc code.

For heaps and arenas, we know:  
* One heap only belongs to one arena.  
* One arena could contain multiple heaps. `main arena` is an exception, because it can get contiguous memory by moving `brk`, so there is no `heap_info` part in `main arena`. For `thread arena`, once heap is exhausted, new heap need be mmaped, maybe it's not contiguous with heap before, hence `heap_info` is needed.  
* One arena could be shared between threads, that why there is a `mutex` in arena data structure.  
* Data structure `arena` is placed on the initial heap of that arena.  
* For 32-bit arch, each heap is as big as 1MB (1024*1024), for 64-bit arch, heap size is 64MB (16MB alignment).

<!--more-->

```bash
# thread arena
                 Heap 1                    Heap 2
    +------+===============+<-----+  +===============+ low
    |      |_____ar_ptr____|---v--|--|_____ar_ptr____|
    |      |______prev_____|   |  +--|______prev_____|
heap_info  |______size_____|   |     |______size_____|
    |      \               \   |     \               \
    |      /               /   |     /               /
    `------|_______________|   |     |_______________|
           |     arena     |<--+     |               |
           |      ...      |         |               |
           |     bins[N]   |         |               |
           |      top      |---+     |               |
           |      ...      |   |     |               |
           |_______________|   |     |     chunks    |
           |               |   |     |               |
           |     chunks    |   |     |               |
           |_______________|   +---->|___top_chunk___| high
	   
# old top chunk became a free chunk.

# main arena
                  Heap 
	   +===============+<--- chunk starts at the very beginnig
	   |               |
	   |               |
	   |               |    main_arena as a static variable in malloc code.
	   \               \           +===============+
	   /               /           |     mutex     |
	   |               |           |      ...      |
	   |               |           |     bins[N]   |
	   |               |     +-----|      top      |
	   |               |     |     |      ...      |
	   |___top_chunk___|<----+     |_______________|
```

> **bins**

**fastbin:** mfastbinptr  fastbins[NFASTBINS];  

* 10 bins: 16 bytes, 24 bytes, 32 bytes...respectively.  
* Max size of chunk is 64 bytes initially.  
* LIFO, single linked list, insertion and deletion happen at front end.  
* No coalescence.  

mchunkptr  bins[NBINS \* 2 - 2];  

**unsorted bin:** bins-1;  

* Chunks of any size larger than maximum fastbin size.  
* LRU, doubly linked list, insertion happens at front end while deletion at back end.
* free()'d chunk is temporarily placed here, after next `malloc()/relloc()` and this chunk isn't allocated again, the chunk will be placed in small bin or large bin.

**small bin:** bins-2~bins-63;  

* Chunk size < 512 bytes, 16 bytes, 24 bytes...
* 62 bins, LRU  

**large bin:** bins-64~bins-126;  

* Chunk size >= 512 bytes  
* bins-64~bins-95(32 bins, 64 bytes apart): 512~568bytes, 576~632 bytes, ...  

**whatever left:** bins-127

Logically, there's no `bins-0`, every one pair of `bins[2x], bins[2x+1]` holds the value of `fd, bk` respectively. `bin_at(m, i)` will return a pointer points to 8 bytes(32-bit OS) backwards, then `fd, bk` will fall into `bins[2i-2], bins[2i-1]` accordingly. Be aware there are differences between glibc nowadays and glibc past.  

**NOTE:**

If a chunk next to top chunk, then when it's free()'d it will be coalesced with top chunk instead of being insert into any of bins.  

```bash
+===============+ low
|               |
|               |<- bin_at(m, 1)
|               |
|____bins[0]____|<- bin_at(m, 2)
|____bins[1]____|
|____bins[2]____|
|____bins[3]____|
```
```cpp
#define bin_at(m, i) \
  (mbinptr) (((char *) &((m)->bins[((i) - 1) * 2]))			      \
	     - offsetof (struct malloc_chunk, fd))
```

> **sbrk() and mmap()**

Internally, `malloc()` calls `sbrk()` or `mmap()` when heap(s) run out of space. 
* For `main arena`, `sbrk()` moves `brk` upwards to expand the heap.  
* For `thread arena`, new memory is `mmap()'d` as new heap.  

We can get new chunk only from top chunk, if top chunk isn't enough then `sbrk()`/`mmap()` comes on the stage.  Once there're free chunks in `bin`, it could be possible that new memory request can be satisfied by old chunks in `bin`.  

`bin`: double/single linked list of free chunks.  
`brk`: program's break location.  

There's a threshold between `arena's heap` and `mmap()`, for requested memory amount less than `M_MMAP_THRESHOLD`(default 128KB), use `heap` from `main arena` or `thread arena` otherwise use `mmap()` to directly map a memory block and set `IS_MMAPPED`.  

```bash
+===============+ high
|               |
|               |
|               |
|               |<- start_brk/brk
|               |<- random offset if aslr turned on
|_____.bss______|
```

> **free()**

Smaller chunks fit into `fastbins` will be placed into fastbins, bigger ones will be placed into `unsorted bin`.   

Chunk will be consolidated with previous or next chunk if they are free and merged chunk will be placed into `unsorted bin`.

Chunk(except fastbin chunk) which next to `top` chunk will goes into `top`. 


> **malloc()**

For small chunk request:

1. Check fastbins if exact size of the request is matched.
2. Check smallbins if exact size of the request is matched.
3. Check unsorted bin, while unsorted bin not empty, LOOP:
	1. Only 1 chunk in the unsorted bin and it's `last_remainder` then split and reattach it, return.
	2. Remove traversed chunk from unsorted bin, if size of the chunk match exactly with chunk requested, return.
	3. Place removed chunk into bin.
	4. Repeat at most MAX_ITERS(10000) times.
4. Check bins, start with size next to the request, if no bin suitable, try top chunk, otherwise LOOP: 
	1. Find adequate chunk.
	2. Split and place remainder to `unsorted bin` and set `last_remainder`. return.
	3. Repeat.
5. Top chunk: if top chunk is big enough, split and return otherwise if there still exist some fastbins chunks, consolidate these chunks and restart from step 3 again or if there's no fastbins chunk left then just extend `top` chunk and restart from step 3.

For large chunk request:

1. Consolidates fastbins first.
2. Check unsorted bin, LOOP:
	1. Remove traversed chunk from unsorted bin, if it's a exact fit, return.
	2. Place removed chunk into bin.
	3. Repeat at most MAX_ITERS(10000) times.
3. Find smallest match from current bin, split and place remainder into `unsorted bin`. return.
4. Check bins, start with size next to the request, if no bin left, try top chunk, otherwise LOOP:
	1. Scan bins for next smallest matched size, split and place remainder into `unsorted bin`. return.
	2. Repeat.
5. Top chunk: if top chunk is big enough, split and return otherwise if there still exist some fastbins chunks, consolidate these chunks and restart from step 2 again or if there's no fastbins chunk left then just extend `top` chunk and restart from step 2.

> **malloc_consolidate()**

Consolidates fastbins chunks, puts merged chunks into `unsorted bin` or `top` if the fastbins chunk is next to `top`.


> **unlink()**

`free()` triggers `unlink()` to consolidate two chunks and remove target chunk from binlist. Only valid for arena chunks, since there is no bin for mmap()'d chunks.

```cpp
#define unlink( P, BK, FD ) {   \
       BK = P->bk;              \
       FD = P->fd;              \
       FD->bk = BK;             \
       BK->fd = FD;             \
}
```
```bash
+-----+-----+-----+-----+
|prev |size | fd  | bk  |
+-----+-----+-----+-----+
|                 |
P               P + 12
```

Since P and FD is treated as mchunkptr, we have equations:  
`P->bk = P + 12`  
`FD->bk = FD + 12`  
Hence value of `bk` will be written to `fd + 12`.  
This is how unlink() technique be applied.  

> **The House of Mind**

```bash
free()
 |
 `-->public_fREe(Void_t* mem)
      |
      `-->mchunkptr p = mem2chunk(mem);
      |
      `-->mstate ar_ptr = arena_for_chunk(p);
      |                    |
      |                    `-->NON_MAIN_ARENA == false
      |                    |    |
      |                    |    `-->return &main_arena;
      |                    |
      |                    `-->NON_MAIN_ARENA == true
      |                         |
      |                         `-->find heap_info to extract ar_ptr in it.
      |
      `-->_int_free(ar_ptr, mem);
```

What important in _int_free() is:

```cpp
void _int_free(mstate av, Void_t* mem) {
    .....
    bck = unsorted_chunks(av);
    fwd = bck->fd;
    p->bk = bck;
    p->fd = fwd;
    bck->fd = p;
    fwd->bk = p;
    .....
}
```

This snippet of code tell us that `chunk p` will be insert into a doubly linked list. `unsorted_chunks(av)` returns **address** of `av->bins[0]` - `8`(unsorted bin).  

**fake arena**

```bash
+===============+
|_____mutex_____|
|_____flags_____|
|  fastbinsY[0] |
|  fastbinsY[1] |
|      ...      |
|_______________|
|______top______|
|_last_remainder|
|    bins[0]    |------>+===============+
|    bins[1]    |       |___prev_size___|
|      ...      |       |______size_____|
|_______________|       |_______fd______|
|      ...      |       |_______bk______|
|_______________|       |      ...      |
                        |_______________|

```

Because we can make a whole fake arena, what's in `bin[0]` will not be a problem.  

```bash
+===============+ low
|               |<- chunkptr
|               |
|_______fd______|<- mem1 = malloc(1024); # e.g. 0x08000028
|_______bk______|# Will be overwritten to fd, bk after free();
|_____mutex_____|<- fake arena
|_____flags_____|
|      ...      |
|_______________|<- prev_size(mem1 + 1024)
|_____0x409_____|<- size
|AAAAAAAAAAAAAAA|
\               \<- fake chunks
/               /
|               |
|____ar_ptr_____|<- fake heap_info # e.g. 0x08100000 = heap_for_ptr(mem2);
|      ...      |
\      what     \
/      ever     /
|      ...      |
|___prev_size___|<- p (nop; jmp 0xc)
|______size_____|
|_______fd______|<- mem2 = malloc(1024); # e.g. 0x08100238
|_______bk______|
|      ...      |
|   SHELLCODE   |
|      ...      |
|_______________|
```

Finally, `fwd = bck->fd = bins[0]`, `fwd->bk = *(bins[0] + 12) = p`, hence, we could overwrite one entry to deliver shellcode.  

> **The House of Mind - Fastbin Method**

Let's look at some old days source code.

```cpp
#define fastbin_index(sz) ((((unsigned int)(sz)) >> 3) - 2)

set_fastchunks(av);
fb = &(av->fastbins[fastbin_index(size)]);
p->fd = *fb;
*fb = p;
```

If `size` field of chunk `p` is overwritten to 8, then we got `fb = &(av->fastbins[-1]);`. `fb` is the address of `av->max_fast`(`av->flags` nowadays), so if we could make a fake `ar_ptr`(`av`) to point somewhere, then we can write `p` to `*(ar_ptr + 4)`. By this, a data-overwrite could be applied to `ret address` of target function.   

> **The House of Prime**

The main goal in `The House of Prime` is to use fake arena to allocate memory which is actually from stack.  

> **The House of Spirit**

After we overwrite a pointer to allocated memory, once this memory is freed, it'll be collected back into `fastbins[]`, when new small chunk(size equals to `av->fast_max` - 8) is requested, the older one will be used, it could point anywhere, hence we get the power to overrun `save eip`.  

> **The House of Force**

Hack `av->top`, hence we can get a new chunk from anywhere(e.g. stack). Again, `saved eip` overwritten becomes possible.  

> **The House of Lore**

WIP

> **off-by-one overwrite**

Disclosed by Google Project Zero Team in 2014. The off-by-one vulnerability could be found at `strcpy(dest, src)` since `strcpy()` copies `strlen(src)` chars PLUS 1 byte `NUL`.

```bash
+===============+
|      size     |
|   prev_size   |--+ <- chunkp3
|               |  |
|               | user data
|       bk      |  |
|       fd      |--+
|      size     |
|   prev_size   |<- chunkp2
|               |
|               |
|       bk      |
|       fd      |
|      size     |
|   prev_size   |<- chunkp1
|_______________|
```

**NOTE:** Besides heap alignment, memory block from `fd` to `prev_size` is return to user as requested by `malloc()`, hence `user data` is next to `size` field of next chunk.  
* When `off-by-one overwrite` happens at `chunkp2`, `NUL` will be written to `chunkp3->size` leading PREV_INUSE of chunkp3 to be unset.
* When chunkp1 is `free()d`, glibc will try to `unlink()` chunkp2 from bins and consolidate chunkp1 and chunkp2. This is where we can do something.  

```cpp
#define unlink(P, BK, FD) { 
  /*
   * bypass heap hardening by assign
   * P->fd = P, P->bk = P
   * now, FD == BK == P
   */
  FD = P->fd;
  BK = P->bk;
  if (__builtin_expect (FD->bk != P || BK->fd != P, 0))
  FD->bk = BK;
  BK->fd = FD;
  P->fd_nextsize->bk_nextsize = P->bk_nextsize;
  P->bk_nextsize->fd_nextsize = P->fd_nextsize;
}
```

Write arbitrary 4-byte at P->bk_nextsize to P->fd_nextsize + 20 and P->fd_nextsize to P->bk_nextsize + 16, which means that both bk_nextsize and fd_nextsize need to point somewhere writable.  
`tls_dtor_list` is a choice. `tls_dtor_list` is a pointer to list contains a bunch of functions executing one by one when `exit()` happens.  
`P->fd_nextsize = tls_dtor_list - 20` =>> `tls_dtor_list` points to `dtor_list` on heap/stack.  
`P->bk_nextsize = stack/heap` =>> `bk_nextsize` points to fake `dtor_list` on heap or stack.  


> **UAF**

**U**se **A**fter **F**ree comes up when there's an operation on a memory block which already free()'d.  
Although it's free()'d, but some contents are still there, makes further utilization possible.  


[ref 0 bh-usa-07-ferguson-WP](http://www.blackhat.com/presentations/bh-usa-07/Ferguson/Whitepaper/bh-usa-07-ferguson-WP.pdf)  
[ref 1 MallocInternals](https://sourceware.org/glibc/wiki/MallocInternals)  
